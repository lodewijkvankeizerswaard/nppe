{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the distance performance metric over multiple values of K\n",
    "\n",
    "This notebook contains the code to visualise a computed posterior by `results.py`. The `filename` variable has to be changed to the name of the file containing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "filename = 'path/to/posterior.csv'\n",
    "aggregation = pd.read_csv(filename)\n",
    "\n",
    "pta_sigmas = [0.03, 0.05, 0.1]\n",
    "metrics = [\"l1\", \"linf\", \"lninf\" ]\n",
    "param_dropouts = aggregation[\"param_dropout\"].unique()\n",
    "\n",
    "param_drops_colors = ['#DDAA33', '#004488', '#000000']\n",
    "ks = aggregation[\"K\"].unique()\n",
    "\n",
    "for pta_sigma in pta_sigmas:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=len(metrics), figsize=(len(metrics)*3, 2.6))\n",
    "    for i, metric in enumerate(metrics):\n",
    "        \n",
    "        # Add model performance lines\n",
    "        for j, param_drop in enumerate(param_dropouts):\n",
    "            df = aggregation[(aggregation[\"param_dropout\"] == param_drop) & (aggregation[\"p_theta_alpha_sigma\"] == pta_sigma)]\n",
    "            means = [df[df[\"K\"] == k][metric].mean() for k in ks]\n",
    "            stds = [df[df[\"K\"] == k][metric].std() for k in ks]\n",
    "            sns.lineplot(x=ks, y=means, color=param_drops_colors[j], label=param_drop, legend=False, ax=ax[i])\n",
    "            ax[i].fill_between(ks, [m - s for m, s in zip(means, stds)], [m + s for m, s in zip(means, stds)],\n",
    "                            color=param_drops_colors[j], alpha=0.2)\n",
    "            ax[i].set_xscale('log')\n",
    "\n",
    "        # Add random baseline\n",
    "        random_df = aggregation[(aggregation[\"p_theta_alpha_sigma\"] == pta_sigma)]\n",
    "        random = [df[df[\"K\"] == k][f\"{metric}-random\"].mean() for k in ks]\n",
    "        random_std = [df[df[\"K\"] == k][f\"{metric}-random\"].std() for k in ks]\n",
    "        sns.lineplot(x=ks, y=random, color=\"black\", label=\"random\", legend=False, ax=ax[i], linestyle=\"--\")\n",
    "\n",
    "        # Add best performance line\n",
    "        best_df = aggregation[(aggregation[\"p_theta_alpha_sigma\"] == pta_sigma)]\n",
    "        best = [df[df[\"K\"] == k][f\"{metric}-best\"].mean() for k in ks]\n",
    "        best_std = [df[df[\"K\"] == k][f\"{metric}-best\"].std() for k in ks]\n",
    "        sns.lineplot(x=ks, y=best, color=\"black\", label=\"best\", legend=False, ax=ax[i])\n",
    "\n",
    "    ax[-1].legend(bbox_to_anchor=(1.02, 0.7), loc='upper left', frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
